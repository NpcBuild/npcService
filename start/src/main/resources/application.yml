server:
  port: 1314
spring:
  application:
    name: NPC
  profiles:
    active: @profiles.active@
    include: system,pay
  servlet:
    multipart:
      enabled: true
      max-file-size: 100MB
      max-request-size: 100MB
  data:
    elasticsearch:
      repositories:
        enabled: true
      client:
#        是否正确？
        rest:
          endpoints: 127.0.0.1:9200
          username:
          password:
  quartz:
#      将 Quartz 持久化方式修改为 jdbc
    job-store-type: jdbc
    jdbc:
      initialize-schema: ALWAYS # 禁用Quartz初始化数据库表
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/yf?autoReconnect=true&useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=CONVERT_TO_NULL&useSSL=false&allowPublicKeyRetrieval=true
    password: root
    username: root
    type: com.alibaba.druid.pool.DruidDataSource # 指定数据源类型
    ############### 连接池 配置 ###############
    druid:
      # 配置初始化大小、最小、最大
      initial-size: 5
      min-idle: 10
      max-active: 20
      # 配置获取连接等待超时的时间（单位：毫秒）
      max-wait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      time-between-eviction-runs-millis: 2000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 600000
      max-evictable-idle-time-millis: 900000
      # 用来测试连接是否可用的SQL语句,默认值每种数据库都不相同,这是mysql
      validation-query: select 1
      # 应用向连接池申请连接，并且testOnBorrow为false时，连接池将会判断连接是否处于空闲状态，如果是，则验证这条连接是否可用
      test-while-idle: true
      # 如果为true，默认是false，应用向连接池申请连接时，连接池会判断这条连接是否是可用的
      test-on-borrow: false
      # 如果为true（默认false），当应用使用完连接，连接池回收连接的时候会判断该连接是否还可用
      test-on-return: false
      # 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle
      pool-prepared-statements: true
      # 要启用PSCache，必须配置大于0，当大于0时， poolPreparedStatements自动触发修改为true，
      # 在Druid中，不会存在Oracle下PSCache占用内存过多的问题，
      # 可以把这个数值配置大一些，比如说100
      max-open-prepared-statements: 20
      # 连接池中的minIdle数量以内的连接，空闲时间超过minEvictableIdleTimeMillis，则会执行keepAlive操作
      keep-alive: true
      # Spring 监控，利用aop 对指定接口的执行时间，jdbc数进行记录 todo 修改成对应AOP
      aop-patterns: "com.springboot.template.dao.*"
      ########### 启用内置过滤器（第一个 stat必须，否则监控不到SQL）##########
      filters: stat,wall,log4j2
      # 自己配置监控统计拦截的filter
      filter:
        # 开启druiddatasource的状态监控
        stat:
          enabled: true
          db-type: mysql
          # 开启慢sql监控，超过2s 就认为是慢sql，记录到日志中
          log-slow-sql: true
          slow-sql-millis: 2000
        # 日志监控，使用slf4j 进行日志输出
        slf4j:
          enabled: true
          statement-log-error-enabled: true
          statement-create-after-log-enabled: false
          statement-close-after-log-enabled: false
          result-set-open-after-log-enabled: false
          result-set-close-after-log-enabled: false
      ########## 配置WebStatFilter，用于采集web关联监控的数据 ##########
      web-stat-filter:
        enabled: true
        url-pattern: /*                 # 过滤所有url
        exclusions: "*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*" # 排除一些不必要的url
        session-stat-enable: true       # 开启session统计功能
        session-stat-max-count: 1000    # session的最大个数,默认100
      ########## 配置StatViewServlet（监控页面），用于展示Druid的统计信息 ##########
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*           # 访问内置监控页面的路径，内置监控页面的首页是/druid/index.html
        reset-enable: false             # 不允许清空统计数据,重新计算
        login-username: root            # 配置监控页面访问密码
        login-password: root
        allow: 127.0.0.1                # 允许访问的地址，如果allow没有配置或者为空，则允许所有访问
        deny:                           # 拒绝访问的地址，deny优先于allow，如果在deny列表中，就算在allow列表中，也会被拒绝
  redis:
    host: localhost
    timeout: 1000   #连接超时时间
    database: 0
    cluster:
      nodes:
        - localhost:6380
        - localhost:6381
        - localhost:6382
        - localhost:6383
        - localhost:6384
        - localhost:6385
      jedis:
        pool:
          max-active: 10
          max-idle: 8   #最大维持连接数
          min-idle: 2
          max-wait: 100   #最大等待连接超时时间
  mail:
    host: smtp.qq.com
    username: 1623285565@qq.com
    password: "ophlijooeeadbcid"
    #  启动SSL时的配置
    smtp:
      socketFactory:
        class: javax.net.ssl.SSLSocketFactory
        fallback: false
        port: 465
  kafka:
    bootstrap-servers: #定义主机列表
      localhost:9092
    template:
      default-topic: yftopic   #定义主题名称
#      loginEmail-topic:loginMailTopic
      createOrder-Topic: createOrderTopic   # 处理秒杀商品的主题
    producer: #定义生产者配置
      key-serializer: org.apache.kafka.common.serialization.StringSerializer   # 消息的 key 的序列化
      #      value-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 value 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
#      retries: 3 #发送失败时，重试发送的次数  此值需要结合业务场景，重试与否各有千秋(重试，好处：尽可能的确保生产者写入block成功；坏处：有可能时带有顺序写入的数据打乱顺序
      retries: 0 #发送失败时，重试发送的次数  此值需要结合业务场景，重试与否各有千秋(重试，好处：尽可能的确保生产者写入block成功；坏处：有可能时带有顺序写入的数据打乱顺序
    consumer: #定义消费者配置
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      group-id: group-1   #数据分组
      properties:
        spring:
          json:
            trusted:
              packages: com.npc.kafka.domain  #properties.spring.json.trusted.packages 需要配置com.artisan.springkafka.domain 包下的 Message 类们。因为 JsonDeserializer 在反序列化消息时，考虑到安全性，只反序列化成信任的 Message 类。 务必配置
    listener:
      missing-topics-fatal: false   # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
  thymeleaf:
    prefix: classpath:/templates/
    suffix: .html
#    properties:
#      sasl.mechanism: PLAIN    #安全机制
#      security.protocol: SASL_PLAINTEXT   #安全协议
mybatis-plus:
  global-config:
    db-config:
      logic-delete-field: flag # 全局逻辑删除的实体字段名
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  mapper-locations: classpath*:com/npc/**/mapper/mapping/*.xml
#  typeAliasesPackage: com.npc.common.modular.user.model

qiniuyun:
  upload:
    accessKey: Vm7po0hPS-Xuizj-MmjobvoO7bAVSNEhc6fn24j7
    secretKey: 8IODtTNs8J_JTwZ0CQXgjqVdvpMF7kEVi0RmusbP
    bucket: npcnpc
    mkdir: images/
    domain: http://sd71w1ocf.hb-bkt.clouddn.com/

logging:
  file:
    path: ./
    name: logs/${spring.application.name}.log
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} %contextName [%thread] %-5level %logger- %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} %contextName [%thread] %-5level %logger- %msg%n"
  level:
    com.npc.common: DEBUG
    com.npc.core: INFO
  logback:
    rollingpolicy:
      max-history: 7
      max-file-size: 10MB
      total-size-cap: 50MB
#用于OAuth认证
github:
  client:
    clientId: 33cea9420109a2fc5a50
    clientSecret: 9a79e757a1170d44ec519428cc757c6fd67c0afc
    authorizeUrl: https://github.com/login/oauth/authorize
    accessTokenUrl: https://github.com/login/oauth/access_token
    redirectUrl: http://localhost:1314/oauth/redirect
    userInfoUrl: https://api.github.com/user
chatgpt:
#  endpoint: https://api.chatgpt.com/v1/generate
  endpoint: https://api.openai.com/v1/completions
  apiKey: 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

yf:
  basic-dir: "E:\\Data"